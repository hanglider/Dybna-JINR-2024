{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import json\n",
    "import os\n",
    "main_dir = Path(r'data/csv_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# словарь с ключевыми словами по ядерной физике\n",
    "high_energy_physics_terms = set([\n",
    "    \"quark\", \"quarks\", \"lepton\", \"leptons\", \"boson\", \"bosons\", \"Higgs\", \"Higgses\", \n",
    "    \"neutrino\", \"neutrinos\", \"photon\", \"photons\", \"gluon\", \"gluons\", \"proton\", \"protons\", \n",
    "    \"neutron\", \"neutrons\", \"electron\", \"electrons\", \"positron\", \"positrons\", \"antimatter\", \n",
    "    \"antimatters\", \"particle\", \"particles\", \"accelerator\", \"accelerators\", \"collider\", \n",
    "    \"colliders\", \"synchrotron\", \"synchrotrons\", \"hadron\", \"hadrons\", \"meson\", \"mesons\", \n",
    "    \"fermion\", \"fermions\", \"muon\", \"muons\", \"tau\", \"taus\", \"graviton\", \"gravitons\", \n",
    "    \"supersymmetry\", \"supersymmetries\", \"quantum\", \"quantums\", \"chromodynamics\", \n",
    "    \"strong_force\", \"strong_forces\", \"weak_force\", \"weak_forces\", \"electromagnetic_force\", \n",
    "    \"electromagnetic_forces\", \"standard_model\", \"standard_models\", \"quantum_field_theory\", \n",
    "    \"quantum_field_theories\", \"spontaneous_symmetry_breaking\", \"grand_unification\", \n",
    "    \"grand_unifications\", \"dark_matter\", \"dark_matters\", \"dark_energy\", \"dark_energies\", \n",
    "    \"cosmic_ray\", \"cosmic_rays\", \"black_hole\", \"black_holes\", \"string_theory\", \n",
    "    \"string_theories\", \"extra_dimension\", \"extra_dimensions\", \"tachyon\", \"tachyons\", \n",
    "    \"renormalization\", \"renormalizations\", \"loop_quantum_gravity\", \"loop_quantum_gravities\", \n",
    "    \"fermion\", \"fermions\", \"neutrino_oscillation\", \"neutrino_oscillations\", \"mass\", \"masses\", \n",
    "    \"energy\", \"energies\", \"feynman_diagram\", \"feynman_diagrams\", \"beta_decay\", \"beta_decays\", \n",
    "    \"big_bang\", \"big_bangs\", \"cosmology\", \"cosmologies\", \"superstring_theory\", \n",
    "    \"superstring_theories\",\n",
    "    \"Black Hole physics\",\n",
    "    \"Curved spacetime\",\n",
    "    \"Experimental realizations\",\n",
    "    \"Hawking radiation\",\n",
    "    \"Massless scalar fields\",\n",
    "    \"Quantum field theory\",\n",
    "    \"Quantum many-body systems\",\n",
    "    \"Static spacetime\",\n",
    "    \"Quantum theory\",\n",
    "    \"Bosonic fields\",\n",
    "    \"Nonclassical effects\",\n",
    "    \"Atom-field interaction\",\n",
    "    \"Cavity Quantum Electrodynamics\",\n",
    "    \"Wigner-Yanase skew information\",\n",
    "    \"Jaynes-Cummings model\",\n",
    "    \"Energy gap\",\n",
    "    \"III-V semiconductors\",\n",
    "    \"High electron mobility\",\n",
    "    \"Magneto-transport characteristics\",\n",
    "    \"Quantum optics\",\n",
    "    \"Wave packets\",\n",
    "    \"Quantum state transfers\",\n",
    "    \"Topological charges\",\n",
    "    \"Phase gradient\",\n",
    "    \"Transverse planes\",\n",
    "    \"X-Y model\",\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_articles(keywords: set, df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Find articles in the DataFrame where at least 2 of the keywords are present in the \"Ключевые слова указателя\" column.\n",
    "\n",
    "    Args:\n",
    "    keywords (set): A set of keywords to search for.\n",
    "    df (pd.DataFrame): The DataFrame to search in.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A new DataFrame containing only the rows where at least 2 of the keywords are present in the \"Ключевые слова указателя\" column.\n",
    "    \"\"\"\n",
    "    # Convert the set of keywords to a list of lowercase strings\n",
    "    keywords = [kw.lower() for kw in keywords]\n",
    "\n",
    "    # Filter out rows with NaN values in the \"Ключевые слова указателя\" column and create a copy\n",
    "    if 'Index Keywords' in df.columns:\n",
    "        df.rename(columns={'Index Keywords': 'Ключевые слова указателя'}, inplace=True)\n",
    "    \n",
    "    try:\n",
    "        df_filtered = df.dropna(subset=['Ключевые слова указателя']).copy()\n",
    "    except:\n",
    "        print('NO SUCH COLUMN Ключевые слова указателя')\n",
    "    \n",
    "    # Using .loc to safely modify the DataFrame\n",
    "    df_filtered.loc[:, 'match_count'] = df_filtered['Ключевые слова указателя'].str.lower().str.findall('|'.join(keywords)).str.len()\n",
    "\n",
    "    # Find rows where at least 2 keywords are present in the \"Ключевые слова указателя\" column\n",
    "    mask = df_filtered['match_count'] >= 2\n",
    "\n",
    "    # Return a new DataFrame containing only the matching rows\n",
    "    return df_filtered[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process each file\n",
    "def process_file(file_path, organisations_dict):\n",
    "\n",
    "    # Read CSV file\n",
    "    # WARNING :  ТУТ ВЫЛЕЗАЕТ ОШИБКА\n",
    "    # TODO\n",
    "    df_current = pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    #df_current = df_current.drop(['Том', 'Выпуск','Страница начала','Страница окончания','Количество страниц','Статья №','Год','Идентификатор PubMed','Сокращенное название источника','Тип документа','СТАДИЯ ПУБЛИКАЦИИ','Open Access (открытый доступ)','CODEN','ISBN','Место проведения конференции','Дата конференции','Название конференции','Код конференции','Редакторы','Спонсоры','Адрес для корреспонденции','Текст о финансировании','Сведения о финансировании','Ссылка','Номера молекулярных последовательностей','Химические вещества/CAS','Фирменные наименования','Производители','DOI','ISSN','Язык оригинального документа','Источник','EID','Идентификатор автора(ов)'], axis=1)\n",
    "    df_current = find_articles(keywords=high_energy_physics_terms,df=df_current)\n",
    "\n",
    "            # Filter out rows with NaN values in the \"Ключевые слова указателя\" column and create a copy\n",
    "    if 'Affiliations' in df_current.columns:\n",
    "        df_current.rename(columns={'Affiliations': 'Организации'}, inplace=True)\n",
    "        \n",
    "    if 'Организации' in df_current.columns:\n",
    "            # Split the organisations column by semicolon and explode it\n",
    "            df_current = df_current.assign(Organisation=df_current['Организации'].str.split(';')).explode('Организации')\n",
    "            # Strip whitespace from organisation names\n",
    "\n",
    "            \n",
    "            #Update count in organisations_df\n",
    "            for org_list in df_current['Organisation']:\n",
    "                for org in org_list:\n",
    "                    if(org in organisations_dict):\n",
    "                        organisations_dict[org.strip()] += 1\n",
    "                    else:\n",
    "                        organisations_dict[org.strip()] = 1\n",
    "    \n",
    "    return organisations_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_5_pairs(dictionary):\n",
    "    # Сортируем словарь по значениям в порядке убывания и берём первые 5 пар\n",
    "    top_pairs = sorted(dictionary.items(), key=lambda item: item[1], reverse=True)[:5]\n",
    "    \n",
    "    return dict(top_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для рекурсивного поиска и обработки всех CSV файлов в директориях\n",
    "# ПРОСТО НАПИСАНА ГПТ, МЫ ЕЩЕ НЕ УСПЕЛИ ЕЕ ИСПОЛЬЗОВАТЬ\n",
    "def process_directory(directory_path):\n",
    "    organisations_dict = dict()\n",
    "\n",
    "    # Рекурсивно обходим папки\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith(\".csv\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                print(f\"Обработка файла: {file_path}\")\n",
    "                organisations_dict = process_file(file_path, organisations_dict)\n",
    "\n",
    "\n",
    "    # После обработки всех файлов, группируем результаты по организациям\n",
    "    final_stats = top_5_pairs(organisations_dict)\n",
    "    \n",
    "    return final_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка файла: ./data/2024/china_2024_may_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_jul_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_aug_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_apr_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_apr_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_nov_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_feb_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_oct_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_nov_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_sep_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_dec_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_jun_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_dec_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_feb_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_nov_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_jun_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_apr_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_oct_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_sep_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_oct_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_jun_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_may_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_jul_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_feb_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_jul_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_may_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_may_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_feb_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_jul_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_apr_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_aug_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_nov_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_sep_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_dec_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_dec_(1, 8).csv\n",
      "Обработка файла: ./data/2024/china_2024_oct_(17, 24).csv\n",
      "Обработка файла: ./data/2024/china_2024_aug_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_sep_(9, 16).csv\n",
      "Обработка файла: ./data/2024/china_2024_jun_(24, 31).csv\n",
      "Обработка файла: ./data/2024/china_2024_aug_(1, 8).csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Beijing Key Lab for Source Control Technology of Water Pollution, College of Environmental Science and Engineering, Beijing Forestry University, Beijing, 100083, China': 14,\n",
       " 'State Key Laboratory of Chemistry and Utilization of Carbon Based Energy Resources, College of Chemistry, Xinjiang University, Xinjiang, Urumqi, 830017, China': 13,\n",
       " 'College of Chemistry and Chemical Engineering, Southwest Petroleum University, Chengdu, 610500, China': 12,\n",
       " 'Tsinghua University, Department of Electrical Engineering, Beijing, 100084, China': 12,\n",
       " 'School of Electrical Engineering, Southeast University, Nanjing, 210096, China': 11}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "directory_path = './data/2024'\n",
    "\n",
    "# Обработка всех файлов\n",
    "top_organisations = process_directory(directory_path)\n",
    "top_organisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Beijing Key Lab for Source Control Technology of Water Pollution, College of Environmental Science and Engineering, Beijing Forestry University, Beijing, 100083, China': 14,\n",
       " 'State Key Laboratory of Chemistry and Utilization of Carbon Based Energy Resources, College of Chemistry, Xinjiang University, Xinjiang, Urumqi, 830017, China': 13,\n",
       " 'College of Chemistry and Chemical Engineering, Southwest Petroleum University, Chengdu, 610500, China': 12,\n",
       " 'Tsinghua University, Department of Electrical Engineering, Beijing, 100084, China': 12,\n",
       " 'School of Electrical Engineering, Southeast University, Nanjing, 210096, China': 11}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_organisations)\n",
    "top_organisations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
